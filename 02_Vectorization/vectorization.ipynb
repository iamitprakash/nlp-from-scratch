{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02: Vectorization - Turning Words into Numbers\n",
    "\n",
    "Machines don't understand text; they understand numbers. **Vectorization** is the process of converting text into numerical vectors that machine learning algorithms can process.\n",
    "\n",
    "In this chapter, we will cover:\n",
    "1. **Bag-of-Words (BoW)**: Simple frequency counting.\n",
    "2. **TF-IDF**: Weighing words by their importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag-of-Words (BoW)\n",
    "BoW represents text as a \"bag\" of its words, ignoring grammar and order but keeping track of frequency.\n",
    "\n",
    "We'll use `scikit-learn`, the industry standard for traditional machine learning in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'great' 'log' 'mat' 'on' 'pets'\n",
      " 'sat' 'the']\n",
      "\n",
      "BoW Matrix (as array):\n",
      "[[0 0 1 0 0 0 0 0 1 1 0 1 2]\n",
      " [0 0 0 0 1 0 0 1 0 1 0 1 2]\n",
      " [1 1 0 1 0 1 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'The cat sat on the mat.',\n",
    "    'The dog sat on the log.',\n",
    "    'Cats and dogs are great pets.'\n",
    "]\n",
    "\n",
    "# Initialize the Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Look at the 'Vocabulary' (the words the vectorizer learned)\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "\n",
    "# Look at the resulting matrix (Document-Term Matrix)\n",
    "print(\"\\nBoW Matrix (as array):\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "BoW has a flaw: it treats all words as equally important. But common words like 'the' carry less information than unique words like 'log'.\n",
    "\n",
    "- **TF (Term Frequency)**: How often a word appears in a document.\n",
    "- **IDF (Inverse Document Frequency)**: How rare a word is across *all* documents.\n",
    "\n",
    "TF-IDF gives high scores to words that are frequent in a specific document but rare in the overall collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'great' 'log' 'mat' 'on' 'pets'\n",
      " 'sat' 'the']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "        and       are       cat      cats       dog      dogs     great  \\\n",
      "0  0.000000  0.000000  0.427554  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.427554  0.000000  0.000000   \n",
      "2  0.408248  0.408248  0.000000  0.408248  0.000000  0.408248  0.408248   \n",
      "\n",
      "        log       mat        on      pets       sat       the  \n",
      "0  0.000000  0.427554  0.325166  0.000000  0.325166  0.650331  \n",
      "1  0.427554  0.000000  0.325166  0.000000  0.325166  0.650331  \n",
      "2  0.000000  0.000000  0.000000  0.408248  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "import pandas as pd # Let's use pandas for a prettier view\n",
    "df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up Exercise\n",
    "1. Define a new list of 5 sentences related to a topic (e.g., Space, Cooking, or Sports).\n",
    "2. Apply `TfidfVectorizer` to it.\n",
    "3. Find the word with the highest TF-IDF score in the first document. Hint: You can use `df.iloc[0].sort_values(ascending=False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4608df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in the 첫번째 (first) document:\n",
      "stunning    0.327113\n",
      "distant     0.327113\n",
      "hubble      0.327113\n",
      "has         0.327113\n",
      "nebulas     0.327113\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Result: The most important word in Document 1 is 'stunning' with a score of 0.3271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define 5 sentences about Space\n",
    "space_corpus = [\n",
    "    \"The Hubble Space Telescope has captured stunning images of distant nebulas.\",\n",
    "    \"Mars is often called the Red Planet because of its iron oxide surface.\",\n",
    "    \"Black holes are regions of space-time where gravity is so strong nothing escapes.\",\n",
    "    \"The International Space Station orbits Earth every ninety minutes.\",\n",
    "    \"Astronauts training for moon missions often practice in extreme environments.\"\n",
    "]\n",
    "\n",
    "# 2. Apply TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(space_corpus)\n",
    "\n",
    "# Create a DataFrame for easy visualization\n",
    "df_space = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), \n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# 3. Find the word with the highest TF-IDF score in the first document\n",
    "# We look at index 0 (the first sentence about Hubble)\n",
    "first_doc_scores = df_space.iloc[0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top words in the 첫번째 (first) document:\")\n",
    "print(first_doc_scores.head(5))\n",
    "\n",
    "# Extract the top word\n",
    "top_word = first_doc_scores.index[0]\n",
    "top_score = first_doc_scores.values[0]\n",
    "\n",
    "print(f\"\\nResult: The most important word in Document 1 is '{top_word}' with a score of {top_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
