{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NLP Foundations: From Text to Structure\n",
        "\n",
        "Welcome to your first step in learning NLP! Natural Language Processing is the field of AI that gives machines the ability to understand, interpret, and generate human language.\n",
        "\n",
        "In this notebook, we'll cover the essential foundations:\n",
        "1. **Tokenization**: Breaking down text into smaller units (tokens).\n",
        "2. **Stop Word Removal**: Filtering out common words that don't carry much meaning.\n",
        "3. **Stemming & Lemmatization**: Reducing words to their base or root form.\n",
        "\n",
        "First, let's make sure we have the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (3.9.2)\n",
            "Requirement already satisfied: spacy in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (3.8.11)\n",
            "Requirement already satisfied: click in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from nltk) (2026.1.15)\n",
            "Requirement already satisfied: tqdm in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from nltk) (4.67.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (2.12.5)\n",
            "Requirement already satisfied: jinja2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (80.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amitprakash/NLP/venv/lib/python3.13/site-packages (from jinja2->spacy) (3.0.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tokenization\n",
        "Tokenization is the process of splitting a string into individual words or tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Hello there! Welcome to the world of NLP. It's fascinating, isn't it?\n",
            "Words: ['Hello', 'there', '!', 'Welcome', 'to', 'the', 'world', 'of', 'NLP', '.', 'It', \"'s\", 'fascinating', ',', 'is', \"n't\", 'it', '?']\n",
            "Sentences: ['Hello there!', 'Welcome to the world of NLP.', \"It's fascinating, isn't it?\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/amitprakash/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Hello there! Welcome to the world of NLP. It's fascinating, isn't it?\"\n",
        "\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(f\"Original: {text}\")\n",
        "print(f\"Words: {words}\")\n",
        "print(f\"Sentences: {sentences}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Stop Word Removal\n",
        "Stop words are common words like 'the', 'is', 'in', etc., which appear frequently but carry little unique meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words after stop-word removal: ['Hello', '!', 'Welcome', 'world', 'NLP', '.', \"'s\", 'fascinating', ',', \"n't\", '?']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/amitprakash/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = [w for w in words if not w.lower() in stop_words]\n",
        "\n",
        "print(f\"Words after stop-word removal: {filtered_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Stemming vs. Lemmatization\n",
        "Both aim to reduce words to their root form, but they do it differently:\n",
        "- **Stemming**: Often chops off the end of words using crude rules (e.g., 'playing' -> 'play', 'better' -> 'bet').\n",
        "- **Lemmatization**: Uses a dictionary to find the actual linguistic root (e.g., 'better' -> 'good')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/amitprakash/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/amitprakash/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word                 Stemming             Lemmatization       \n",
            "rocks                rock                 rocks               \n",
            "corpora              corpora              corpora             \n",
            "better               better               good                \n",
            "playing              play                 playing             \n",
            "happier              happier              happy               \n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "example_words = [\"rocks\", \"corpora\", \"better\", \"playing\", \"happier\"]\n",
        "\n",
        "print(\"{0:20} {1:20} {2:20}\".format(\"Word\", \"Stemming\", \"Lemmatization\"))\n",
        "for w in example_words:\n",
        "    print(\"{0:20} {1:20} {2:20}\".format(w, ps.stem(w), lemmatizer.lemmatize(w, pos='a')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wrap-up Task\n",
        "Try creating a simple function that takes a raw string and returns a list of cleaned, lemmatized tokens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cda98a6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
